{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ALP presentation\n",
    "======\n",
    "\n",
    "Asynchronous Learning Platform - by [Thomas Boquet](https://github.com/tboquet) and [Paul Lemaître](https://github.com/DrAnaximandre)\n",
    "\n",
    "\n",
    "Some features:\n",
    "* open source!\n",
    "* Neural Network [keras](https://keras.io/) library support\n",
    "* partial [sklearn](http://scikit-learn.org/stable/) library support\n",
    "* GPU or CPU broker that dispaches experiments\n",
    "* 2 databases that store the models and the results\n",
    "* a CLI!\n",
    "* a style-transfered image of a mountain goat.\n",
    "\n",
    "\n",
    "<img src=\"last_bouquetin.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Outline\n",
    "====\n",
    "\n",
    "* Why ALP?\n",
    "* What kind of model can I use?\n",
    "* What do I need to run ALP? What is inside ALP? How stable is it?\n",
    "* How could ALP help me ?\n",
    "* Live coding!\n",
    "* Request for features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do we develop ALP?\n",
    "=======\n",
    "\n",
    "* **Assertion** : when doing ML to solve a problem, we spend more time working on \n",
    "    + building a model\n",
    "    + testing different architectures\n",
    "    + comparing results\n",
    "    \n",
    "    than actually work on the ideas that will solve the problem. \n",
    "\n",
    "\n",
    "* **Our proposition**: to help that process, we develop an Asynchronous Learning Platform (ALP) that uses the hardware (CPU+GPU) at a convenient capacity and manages the models.\n",
    "\n",
    "\n",
    "* **Core idea** : that platform relies on independant services running on Docker containers. To the end-user, it is just a matter of importing the right modules in a Notebook. ALP will run the experiments asynchronously and store the architectures and results in persistant databases.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What kind of model can I use?\n",
    "===\n",
    "\n",
    "* So far the [keras](https://keras.io/) library is supported with the Tensorflow backend.\n",
    "    * out-of-the-box keras models runs seamlessly.\n",
    "    * some tricks are necessary to run your own class/layer/loss (due to serialization challenges).\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "* Several models of the [sklearn](http://scikit-learn.org/stable/) library are supported.\n",
    "    * Not the ensemble models yet (such as Random Forests).\n",
    "    * The support of sklearn is mostly historical / for testing or tutorial purposes.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do I need to run ALP? \n",
    "===\n",
    "You need to use a machine running Ubuntu to use ALP, with docker or nvidia-docker if you have a NVIDIA GPU.\n",
    "\n",
    "\n",
    "What is inside ALP? \n",
    "===\n",
    "ALP relies on Docker, RabbitMQ, Celery, MongoDB and nvidia-docker among other. It also supports interfacing with Fuel thus depends (so far) on Theano. It’s implemented in Python. All the dependencies *should be* in the Docker images. The first launch of ALP might be a bit long as the images need to be pulled, depending on your bandwidth.\n",
    "\n",
    "\n",
    "How stable is it?\n",
    "===\n",
    "0.3.0 is the latest stable release. It seldom crashes if the user does not try funky operations. An effort was put onto continuous integration (using Travis) during the first stages of the development.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could ALP help me?\n",
    "===\n",
    "\n",
    "We believe it might be useful for several applications such as:\n",
    "\n",
    "* **hyperparameters/architecture tuning**: ALP can help you in dealing with the tedious task of logging all the architectures, parameters and results. They are all automatically stored in the databases and you just have to select the best model given the validation(s) you specified.\n",
    "* **fitting several models on several data streams**: you have data streams coming from a source and you want to fit a lot of online models, it is easy with ALP. With the support of Fuel generators, you can transform your data on the fly.\n",
    "* **post analysis**: extract and explore the parameters of models given their score on several data blocks. Sometimes it can be helpful to visualise the successful set of parameters.\n",
    "* **model deployment in production**: when a model is trained, you can load it and deploy it quickly in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Live coding\n",
    "===\n",
    "\n",
    "Let us go through some basic exemples in a Jupyter Notebook.\n",
    "\n",
    "* defining a sklearn model and run it in alp\n",
    "* simple hyperparameter tuning in alp (with asynchronous fit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Request for features\n",
    "===\n",
    "\n",
    "Let us discuss the features you need so that we can implement them. Some ideas:\n",
    "\n",
    "* so far the easiest way to work as a team on a machine is to launch a worker by user and attribute the ressources (eg that amount of memory per user/ that many GPUs per user). We could develop a fancier version that gives unused ressources if needed.\n",
    "* support of Pytorch models\n",
    "* support of NiftyNet\n",
    "* abstract backend\n",
    "\n",
    "\n",
    "You can always [open an issue on the repo](https://github.com/tboquet/python-alp/issues)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
